{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e2780de-74d8-42c1-85cd-034a6e1da6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|default_exp xformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87866773-6fbb-43d2-85d9-c010e9db5841",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4c137d-61dd-429e-b9b9-d4dc710b6ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn, optim, tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from functools import partial\n",
    "\n",
    "import fastcore.all as fc\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from datasets import load_dataset\n",
    "import tiktoken\n",
    "\n",
    "from miniai.datasets import * \n",
    "from miniai.activations import *\n",
    "from miniai.learner import *\n",
    "from miniai.conv import * \n",
    "from miniai.resnet import *\n",
    "from miniai.init import * \n",
    "from miniai.sgd import *\n",
    "from miniai.augment import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485ab454-fd93-4244-9267-38136482f012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757ad2bc-630a-409f-b25d-7d6f1556a199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "plt.style.use('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77dcb20e-23e9-443e-8f07-c7cb437f0e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tiny_shakespeare (/Users/leonardourbina/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/b5b13969f09fe8707337f6cb296314fbe06960bd9a868dca39e713e163d27b5e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9100fdbbaf0344419ee731b6ffcb6efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = \"tiny_shakespeare\"\n",
    "dsd = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2471e723-bbc7-4986-b248-d0937824ac59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TConfig:\n",
    "    batch_size = 32\n",
    "    ctx_size = 100\n",
    "    num_workers = False\n",
    "    n_embed = 512\n",
    "    num_heads = 8\n",
    "    head_width = n_embed//num_heads\n",
    "    encoding = 'cl100k_base'\n",
    "    bias = False \n",
    "    dropout = 0.1\n",
    "    fanout = 4 # MLP fanout\n",
    "    act = partial(GeneralReLU, leak=0.1, sub=0.4)\n",
    "    depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ef6115-8d86-457d-8c0c-435274d8c941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = TConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f285e3-7577-494c-8f43-0b43f07b8278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@fc.delegates(Dataset)\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, encoder, config: TConfig, **kwargs): \n",
    "        self.n_vocab = encoder.n_vocab\n",
    "        self.text = tensor(encoder.encode_ordinary(text))\n",
    "    def __getitem__(self, i): \n",
    "        target = torch.zeros(self.n_vocab, dtype=torch.long)\n",
    "        target[self.text[i+config.ctx_size+1]] = 1.\n",
    "        return self.text[i:i+config.ctx_size], target\n",
    "    def __len__(self): return len(self.text) - config.ctx_size - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df0ba3a-e26c-4999-bc7e-397d8f4b07e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(config.encoding)\n",
    "train_ds = TextDataset(dsd['train']['text'][0], enc, config)\n",
    "valid_ds = TextDataset(dsd['validation']['text'][0], enc, config)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=config.batch_size, num_workers=config.num_workers)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=config.batch_size, num_workers=config.num_workers)\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05002498-e182-4cf2-8cc6-dbd09d805883",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 100]), torch.Size([32, 100277]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(dls.train))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdece58a-4868-484b-9bb5-9a2df74c06f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module): # Decoder-only dot product attention\n",
    "    def __init__(self, head_width, ctx_size):\n",
    "        super().__init__()\n",
    "        self.keys = nn.Linear(head_width, head_width, bias=False)     # B, T, C -> B, T, C\n",
    "        self.queries = nn.Linear(head_width, head_width, bias=False)  # B, T, C -> B, T, C\n",
    "        self.values = nn.Linear(head_width, head_width, bias=False)   # B, T, C -> B, T, C\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(ctx_size, ctx_size))) # T, T\n",
    "                \n",
    "    def forward(self, x):\n",
    "        keys = self.keys(x)\n",
    "        queries = self.queries(x)\n",
    "        values = self.values(x)\n",
    "        \n",
    "        B, T, C = keys.shape\n",
    "        cov = queries @ keys.transpose(-2, -1)*C**(-0.5) # (B, T, C) @ (B, C, T) -> (B, T, T) \n",
    "        cov.masked_fill_(self.tril == 0, -torch.inf)\n",
    "\n",
    "        return F.softmax(cov, dim=-1) @ values # (B, T, T) @ (B, T, H) -> (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4890eef-dede-4570-b334-95673156f0ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module): \n",
    "    def __init__(self, head_width, num_heads, ctx_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(head_width, ctx_size) for _ in range(config.num_heads)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = torch.cat([head(x) for head in self.heads], dim=-1)        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "596dd04c-ddc4-4f16-a374-d4e0eef2d454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, config: TConfig):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(config.n_embed * config.num_heads, config.n_embed*config.fanout, bias=config.bias)\n",
    "        self.act = config.act()\n",
    "        self.lin2 = nn.Linear(config.n_embed*config.fanout, config.n_embed, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a035d283-0f41-4090-8a43-b9c1697c89e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config: TConfig):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embed)\n",
    "        self.attn = MultiHeadAttention(config.n_embed, \n",
    "                                       config.num_heads, \n",
    "                                       config.ctx_size)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embed)\n",
    "        self.mlp = MLP(config)\n",
    "    \n",
    "    def forward(self, inp): \n",
    "        x = self.ln_1(inp)\n",
    "        x = self.attn(x)\n",
    "        x = inp + self.mlp(x)\n",
    "        x = self.ln_2(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21248cc7-f89a-4356-bc95-bb22aa9f18b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, config: TConfig):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, config.n_embed, device=device)         #  token embedding\n",
    "        self.position_embedding = nn.Embedding(config.ctx_size, config.n_embed, device=device) #  positional embedding\n",
    "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.depth)])\n",
    "        self.ln = nn.LayerNorm(config.n_embed)\n",
    "        self.project = nn.Linear(config.n_embed, vocab_size)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        B, T = idx.shape\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=device).unsqueeze(0)\n",
    "        \n",
    "        x = self.token_embedding(idx) + self.position_embedding(pos) \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.ln(x)\n",
    "        x = self.project(x)\n",
    "        return x\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return model_iter(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0880351a-7b38-432c-8bec-7bc6d8350c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = TConfig()\n",
    "gpt = GPT(enc.n_vocab, config).to(device)\n",
    "\n",
    "epochs = 5\n",
    "tmax = epochs * len(dls.train)\n",
    "\n",
    "astats = ActivationStats(fc.risinstance(GeneralReLU))\n",
    "metrics = MetricsCB(accuracy=MulticlassAccuracy())\n",
    "sched = BatchSchedCB(partial(optim.lr_scheduler.OneCycleLR, max_lr=3e-4, total_steps=tmax))\n",
    "cbs = [DeviceCB(device=device), astats, metrics, sched, ProgressCB(plot=True)]\n",
    "learn = Learner(gpt, dls, F.cross_entropy, lr=1e-4, cbs=cbs, opt_func=optim.AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "861a6c0b-1099-4593-b590-d589e11db52c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\u001b[0m(65)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     63 \u001b[0;31m        \u001b[0mms_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 65 \u001b[0;31m        hook_fns = {key: [t for t in (hook(l) for l in ms_iters) if t is not None] \n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m                          for key, hook in hooks.items()}\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\u001b[0m(66)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     64 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m        hook_fns = {key: [t for t in (hook(l) for l in ms_iters) if t is not None] \n",
      "\u001b[0m\u001b[0;32m---> 66 \u001b[0;31m                          for key, hook in hooks.items()}\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\u001b[0m(65)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     63 \u001b[0;31m        \u001b[0mms_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 65 \u001b[0;31m        hook_fns = {key: [t for t in (hook(l) for l in ms_iters) if t is not None] \n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m                          for key, hook in hooks.items()}\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: 'generator' object has no attribute 'register_forward_hook'\n",
      "> \u001b[0;32m/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\u001b[0m(65)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     63 \u001b[0;31m        \u001b[0mms_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 65 \u001b[0;31m        hook_fns = {key: [t for t in (hook(l) for l in ms_iters) if t is not None] \n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m                          for key, hook in hooks.items()}\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/p2/0hwfshcj20gblzjrlt3_kvp80000gn/T/ipykernel_12855/2544765029.py\", line 1, in <module>\n",
      "    learn.fit()\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/learner.py\", line 127, in fit\n",
      "    self._fit(train, valid)\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/learner.py\", line 103, in _f\n",
      "    o._callback(f'before_{self.name}')\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/learner.py\", line 168, in _callback\n",
      "    def _callback(self, method_name): run_cbs(self.cbs, method_name, self)\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/learner.py\", line 46, in run_cbs\n",
      "    if method is not None: method(learn)\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\", line 100, in before_fit\n",
      "    self.hooks = Hooks(modules, hook=partial(self.hookfunc, learn))\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\", line 65, in __init__\n",
      "    hook_fns = {key: [t for t in (hook(l) for l in ms_iters) if t is not None]\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\", line 65, in <dictcomp>\n",
      "    hook_fns = {key: [t for t in (hook(l) for l in ms_iters) if t is not None]\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\", line 65, in <listcomp>\n",
      "    hook_fns = {key: [t for t in (hook(l) for l in ms_iters) if t is not None]\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\", line 65, in <genexpr>\n",
      "    hook_fns = {key: [t for t in (hook(l) for l in ms_iters) if t is not None]\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\", line 104, in hookfunc\n",
      "    return self.hook(*args, **kwargs)\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\", line 121, in __init__\n",
      "    super().__init__(m)\n",
      "  File \"/Users/leonardourbina/code/ml/fastai2022p2/miniai/activations.py\", line 29, in __init__\n",
      "    def __init__(self, m): self.hook = m.register_forward_hook(self)\n",
      "AttributeError: 'generator' object has no attribute 'register_forward_hook'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/leonardourbina/mambaforge/envs/fastai/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "learn.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbb2003b-62e8-4ce5-a11a-f92299c8f281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.18, -0.63,  0.78,  ...,  0.66, -0.04, -0.84],\n",
       "         [-0.37, -0.39, -1.51,  ...,  1.43,  0.35, -0.02],\n",
       "         [-0.88,  0.90,  0.29,  ...,  1.12, -1.85, -0.51],\n",
       "         ...,\n",
       "         [-1.46, -0.24,  0.13,  ...,  0.23, -2.42, -0.39],\n",
       "         [-1.03,  0.91, -1.23,  ..., -1.91,  0.20, -1.25],\n",
       "         [-1.21,  0.45,  1.26,  ..., -0.51,  0.42, -0.73]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T = xb.shape\n",
    "pos = torch.arange(0, T, dtype=torch.long, device=device).unsqueeze(0)\n",
    "pos_emb = nn.Embedding(config.ctx_size, config.n_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa569b5e-5e93-48a8-836c-3388bb090637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
